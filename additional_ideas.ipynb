{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a436653",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "551aee69",
   "metadata": {},
   "source": [
    "# More Realistic Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f6941",
   "metadata": {},
   "source": [
    "This is the difference between a \"tutorial follower\" and a \"developer.\" To make this project get you hired in Hong Kong, you need to add **Friction** and **Complexity**.\n",
    "\n",
    "Here are three specific tiers of upgrades you can build on top of your current script.\n",
    "\n",
    "### Tier 1: The \"Realism\" Upgrade (Transaction Costs)\n",
    "**The Problem:** Your current script assumes trading is free. In reality, every trade costs money (commission + slippage). A strategy that makes 10% profit with 1,000 trades might actually lose money once you pay 0.1% per trade.\n",
    "\n",
    "**The Task:**\n",
    "1.  Define a cost variable (e.g., `COST = 0.001` for 10bps).\n",
    "2.  Detect *when* a trade happens. A trade happens when the signal *changes* (e.g., from 0 to 1, or 1 to 0).\n",
    "3.  Subtract the cost from your returns on those specific days.\n",
    "\n",
    "**The Code Add-On:**\n",
    "```python\n",
    "# Calculate when a trade occurs (Buy or Sell)\n",
    "# .diff() calculates the difference between row N and row N-1\n",
    "# If signal goes 0 -> 1, diff is 1. If 1 -> 0, diff is -1.\n",
    "# We take the absolute value because we pay fees on BOTH buying and selling.\n",
    "df['Trades'] = df['Signal'].diff().abs()\n",
    "\n",
    "# Subtract costs from the strategy return\n",
    "# We shift the cost to occur on the day of execution (same as the return)\n",
    "# Note: We fillNA(0) because the first row can't differ from a previous row\n",
    "transaction_cost = 0.001  # 0.1% per trade\n",
    "df['Strategy_Net_Returns'] = df['Strategy_Returns'] - (df['Trades'].shift(1) * transaction_cost)\n",
    "\n",
    "# Re-calculate your cumulative wealth with the Net Returns\n",
    "df['Net_Equity'] = (1 + df['Strategy_Net_Returns']).cumprod()\n",
    "```\n",
    "\n",
    "### Tier 2: The \"Engineer\" Upgrade (Parameter Optimization)\n",
    "**The Problem:** Why did you pick 50 and 200 days? Because a blog told you to?\n",
    "A Quant tests *everything*. Maybe 40 and 180 is better for NVIDIA?\n",
    "\n",
    "**The Task:**\n",
    "Write a loop that tests every combination of \"Short Window\" (10 to 50) and \"Long Window\" (100 to 250) and tells you which pair had the highest Sharpe Ratio.\n",
    "\n",
    "**The Code Structure:**\n",
    "```python\n",
    "best_sharpe = 0\n",
    "best_params = (0, 0)\n",
    "\n",
    "# Nested loops to test combinations\n",
    "for short_window in range(20, 60, 5): # Test 20, 25, 30...\n",
    "    for long_window in range(150, 250, 10): # Test 150, 160...\n",
    "        \n",
    "        # 1. Calculate SMAs with these specific windows\n",
    "        # 2. Generate Signals\n",
    "        # 3. Calculate Sharpe\n",
    "        \n",
    "        if current_sharpe > best_sharpe:\n",
    "            best_sharpe = current_sharpe\n",
    "            best_params = (short_window, long_window)\n",
    "\n",
    "print(f\"Optimal Strategy: Buy at {best_params[0]} / {best_params[1]}\")\n",
    "```\n",
    "*Warning:* If you put this on your resume, be prepared to discuss \"Overfitting.\" (Just because 42/186 worked in the past doesn't mean it will work in the future).\n",
    "\n",
    "### Tier 3: The \"Product\" Upgrade (Interactive Dashboard)\n",
    "**The Problem:** A Jupyter Notebook is ugly. You can't send a notebook to a Recruiter.\n",
    "**The Fix:** Turn your script into a web app using **Streamlit**. It requires no HTML/CSS knowledge, just Python.\n",
    "\n",
    "**The Task:**\n",
    "1.  Install streamlit (`pip install streamlit`).\n",
    "2.  Create a file `app.py`.\n",
    "3.  Add sliders so the user can change the moving averages themselves.\n",
    "\n",
    "**The Code Snippet:**\n",
    "```python\n",
    "import streamlit as st\n",
    "\n",
    "st.title(\"HK Quant Backtester\")\n",
    "\n",
    "# Sidebar for user inputs\n",
    "ticker = st.sidebar.text_input(\"Ticker Symbol\", \"NVDA\")\n",
    "short_w = st.sidebar.slider(\"Short Window\", 10, 100, 50)\n",
    "long_w = st.sidebar.slider(\"Long Window\", 100, 300, 200)\n",
    "\n",
    "# ... [Insert your Backtest Logic Here using these variables] ...\n",
    "\n",
    "# Display results\n",
    "st.line_chart(df[['Strategy_Equity', 'Buy_Hold_Equity']])\n",
    "st.write(f\"Sharpe Ratio: {sharpe:.2f}\")\n",
    "```\n",
    "**The ROI:** You can host this for free on \"Streamlit Cloud\" and put the link in your LinkedIn bio. \"Check out my algorithmic trading engine\" sounds much better than \"I know Python.\"\n",
    "\n",
    "### Which one should you do first?\n",
    "Do **Tier 1 (Transaction Costs)** immediately. It shows you understand that trading isn't free. This is the #1 thing that separates academic projects from industry-ready code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e77c037",
   "metadata": {},
   "source": [
    "# Other Trading Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b84ef0c",
   "metadata": {},
   "source": [
    "To move beyond simple RSI strategies and prove you are \"Quant Material,\" you need to demonstrate you understand **Market Structure** (Volatility) and **Statistical Relationships** (Correlation/Cointegration).\n",
    "\n",
    "Here are three distinct strategy types that act as excellent portfolio projects. They use the same `yfinance` + `pandas` stack but test completely different skills.\n",
    "\n",
    "---\n",
    "\n",
    "### Strategy 1: The \"Volatility Breakout\" (Momentum)\n",
    "*   **The Logic:** Markets alternate between \"Quiet\" (Low Volatility) and \"Explosive\" (High Volatility). This strategy doesn't care about the direction; it bets that a quiet period will be followed by a big move.\n",
    "*   **Why it gets you hired:** It shows you understand **Risk-Adjusted Sizing** (using ATR) rather than just price.\n",
    "\n",
    "**The Code Concept:**\n",
    "1.  Calculate the **ATR** (Average True Range) to measure volatility.\n",
    "2.  Identify a \"squeeze\": When the current ATR is lower than the 30-day average ATR (the calm before the storm).\n",
    "3.  **Signal:** If Price breaks the *Highest High* of the last 20 days + 1 ATR, **BUY**.\n",
    "4.  **Exit:** If Price falls below the *Lowest Low* of the last 10 days, **SELL**.\n",
    "\n",
    "### Strategy 2: \"Pairs Trading\" (Statistical Arbitrage)\n",
    "*   **The Logic:** You find two stocks that are historically \"tied\" together (e.g., Coke & Pepsi, or Gold & Gold Miners). When they drift apart, you Short the winner and Long the loser, betting they will snap back like a rubber band.\n",
    "*   **Why it gets you hired:** This is a true \"Hedge Fund\" strategy. It is **Market Neutral** (you don't care if the market goes up or down, only that the *relationship* holds).\n",
    "\n",
    "**The Code Concept:**\n",
    "You need `statsmodels` for this one.\n",
    "\n",
    "```python\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import coint\n",
    "\n",
    "# 1. Get Data for a Correlated Pair\n",
    "# GLD (Gold ETF) and GDX (Gold Miners ETF) are a classic pair\n",
    "data = yf.download(['GLD', 'GDX'], start='2020-01-01')['Adj Close']\n",
    "\n",
    "# 2. Test for Cointegration (The \"Rubber Band\" Test)\n",
    "# P-value < 0.05 means they are statistically linked\n",
    "score, pvalue, _ = coint(data['GLD'], data['GDX'])\n",
    "print(f\"Cointegration P-Value: {pvalue}\")\n",
    "\n",
    "# 3. Calculate the Spread (The Trading Signal)\n",
    "# We find the Hedge Ratio to make them comparable\n",
    "import statsmodels.api as sm\n",
    "model = sm.OLS(data['GLD'], data['GDX']).fit()\n",
    "hedge_ratio = model.params[0]\n",
    "\n",
    "# The Spread is the difference between the two, adjusted by the ratio\n",
    "data['Spread'] = data['GLD'] - (hedge_ratio * data['GDX'])\n",
    "\n",
    "# 4. Generate Z-Score (How far is the rubber band stretched?)\n",
    "mean_spread = data['Spread'].rolling(window=30).mean()\n",
    "std_spread = data['Spread'].rolling(window=30).std()\n",
    "data['Z_Score'] = (data['Spread'] - mean_spread) / std_spread\n",
    "\n",
    "# 5. Signal: Buy when Z-Score < -2, Sell when Z-Score > 2\n",
    "data['Signal'] = np.where(data['Z_Score'] < -2, 1, np.where(data['Z_Score'] > 2, -1, 0))\n",
    "```\n",
    "\n",
    "### Strategy 3: VWAP Mean Reversion (Institutional Execution)\n",
    "*   **The Logic:** **VWAP** (Volume Weighted Average Price) is the benchmark used by institutions. If the price is significantly below VWAP, it is considered \"cheap\" by big banks. If above, it is \"expensive.\"\n",
    "*   **Why it gets you hired:** It shows you understand **Liquidity** and **Volume**, not just Price.\n",
    "\n",
    "**The Code Concept:**\n",
    "VWAP is not a standard column; you must build it.\n",
    "\n",
    "```python\n",
    "# Assuming you downloaded 'High', 'Low', 'Close', 'Volume'\n",
    "df = yf.download('NVDA', start='2024-01-01', interval='1h') # Intraday data works best\n",
    "\n",
    "# 1. Calculate Typical Price\n",
    "df['Typical_Price'] = (df['High'] + df['Low'] + df['Close']) / 3\n",
    "\n",
    "# 2. Calculate VWAP (Cumulative Price * Volume / Cumulative Volume)\n",
    "# Note: Real VWAP resets every day. For a project, you can use a rolling window.\n",
    "df['VWAP'] = (df['Typical_Price'] * df['Volume']).rolling(window=24).sum() / df['Volume'].rolling(window=24).sum()\n",
    "\n",
    "# 3. Signal\n",
    "# Buy if Price crosses ABOVE VWAP (Bullish confirmation)\n",
    "# OR Buy if Price is 2 Standard Deviations BELOW VWAP (Mean Reversion)\n",
    "```\n",
    "\n",
    "### Recommendation for Your GitHub\n",
    "Add **Strategy 2 (Pairs Trading)** to your repository next.\n",
    "1.  It forces you to use a new library (`statsmodels`).\n",
    "2.  It introduces a statistical concept (Cointegration vs. Correlation).\n",
    "3.  It visually looks impressive when you plot the \"Spread\" snapping back to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87980354",
   "metadata": {},
   "source": [
    "# Fun Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39298024",
   "metadata": {},
   "source": [
    "Since you are currently in **Singapore** (or your system is routed there), and your career goal is **Hong Kong**, let's bridge the gap. \"Fun\" in the Quant world usually means **Visualizations**, **Gambling Mathematics**, or **Alternative Data**.\n",
    "\n",
    "Here are three \"Edutainment\" projects that are technically impressive but actually fun to build and watch.\n",
    "\n",
    "### 1. The \"Monte Carlo\" Casino (Simulating the Future)\n",
    "Instead of backtesting the past, simulate 1,000 possible futures. This is visually mesmerizing and is the foundation of **Value at Risk (VaR)** models used by every bank in Singapore and HK.\n",
    "\n",
    "*   **The Concept:** \"If I invest $10,000 in Bitcoin today, what are the 1,000 different ways this could play out over the next year?\"\n",
    "*   **The Fun Part:** You generate a \"Spaghetti Plot\"â€”a chaotic, beautiful mess of lines showing best-case (Lambo) and worst-case (Zero) scenarios.\n",
    "\n",
    "**The Code Snippet (Matplotlib Magic):**\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup: 1 year, 252 trading days, 1000 simulations\n",
    "days = 252\n",
    "simulations = 1000\n",
    "start_price = 100\n",
    "\n",
    "# Assumptions: 10% expected return, 20% volatility (Change these!)\n",
    "mu = 0.10 / days\n",
    "sigma = 0.20 / np.sqrt(days)\n",
    "\n",
    "# The Math: Geometric Brownian Motion (The standard model for stocks)\n",
    "# We generate random daily shocks\n",
    "shocks = np.random.normal(mu, sigma, (days, simulations))\n",
    "price_paths = start_price * np.cumprod(np.exp(shocks), axis=0)\n",
    "\n",
    "# Visualizing the Chaos\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(price_paths[:, :50]) # Plot first 50 paths to keep it clean\n",
    "plt.title(f'Monte Carlo Simulation: {simulations} Possible Futures')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()\n",
    "```\n",
    "*   **ROI Factor:** This proves you understand **Stochastic Calculus** without needing to write the differential equations on a whiteboard.\n",
    "\n",
    "### 2. The \"Hype Hunter\" (NLP & Sentiment Analysis)\n",
    "Finance isn't just numbers; it's psychology.\n",
    "*   **The Project:** Build a script that scrapes headlines or Reddit (r/WallStreetBets) and correlates \"Hype\" with \"Price.\"\n",
    "*   **The Fun Part:** You get to analyze text data. Does the word \"Moon\" appearing 500 times actually predict a price jump?\n",
    "*   **Tools:**\n",
    "    *   `Library: TextBlob` or `VADER` (for sentiment scores: Positive/Negative).\n",
    "    *   `Library: PRAW` (to scrape Reddit) or `yfinance` news.\n",
    "\n",
    "**Simple Idea:**\n",
    "1.  Download news headlines for Tesla.\n",
    "2.  Score them: +1 (Positive), -1 (Negative).\n",
    "3.  Plot the \"Sentiment Score\" line against the \"Stock Price\" line.\n",
    "4.  *Spoiler:* You will often find they move together!\n",
    "\n",
    "### 3. The \"Singapore vs. Hong Kong\" Showdown (Correlation Heatmaps)\n",
    "Since you are physically in **Singapore** but professionally aimed at **Hong Kong**, analyze the relationship between the two financial hubs.\n",
    "\n",
    "*   **The Project:** A \"Macro-Correlation\" Heatmap.\n",
    "*   **The Data:**\n",
    "    *   **STI (Straits Times Index):** The Singapore Benchmark (`^STI`).\n",
    "    *   **HSI (Hang Seng Index):** The Hong Kong Benchmark (`^HSI`).\n",
    "    *   Add: S&P 500 (`SPY`) and Gold (`GLD`).\n",
    "*   **The Fun Part:** Use `seaborn` to create a colored heatmap.\n",
    "    *   *Question:* When HK crashes, does Singapore crash too? or does money flow from HK to SG? (This is a huge talking point in finance right now).\n",
    "\n",
    "**The \"Pretty Chart\" Code:**\n",
    "```python\n",
    "import seaborn as sns\n",
    "\n",
    "tickers = ['^STI', '^HSI', 'SPY', 'GLD']\n",
    "data = yf.download(tickers, start='2020-01-01')['Adj Close']\n",
    "\n",
    "# Calculate daily returns\n",
    "corr_matrix = data.pct_change().corr()\n",
    "\n",
    "# Plot the Heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Singapore vs. HK vs. USA: Who Moves Together?')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Summary of \"Fun\"\n",
    "1.  **Monte Carlo:** If you like chaos and gambling math.\n",
    "2.  **NLP/Sentiment:** If you like psychology and social media.\n",
    "3.  **Correlation Heatmaps:** If you want to understand the macro-economics of your current location (SG) vs. your target location (HK).\n",
    "\n",
    "**My Advice:** Do the **Monte Carlo** one first. It produces the coolest looking chart to show your friends (or a recruiter), and it makes you feel like a wizard predicting the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cad189d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
